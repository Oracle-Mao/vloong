{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8165da9e-4c20-4794-8d34-e2dd56b4ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50f096e-c3fb-4c82-8b77-5bfed1071f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28389/28389 [00:01<00:00, 16193.22it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path='./data/Train'#存放数据的路径\n",
    "pkl_files = glob(data_path+'/*.pkl')\n",
    "ind_pkl_files = []#存放标签为0的文件\n",
    "ood_pkl_files = []#存放标签为1的文件\n",
    "for each_path in tqdm(pkl_files):\n",
    "    pic = open(each_path,'rb')\n",
    "    this_pkl_file= pickle.load(pic)#下载pkl文件\n",
    "    if this_pkl_file[1]['label'] == '00':\n",
    "        ind_pkl_files.append(each_path)\n",
    "    else:\n",
    "        ood_pkl_files.append(each_path)\n",
    "\n",
    "all_pkl_files=ind_pkl_files+ood_pkl_files\n",
    "\n",
    "random.seed(0)\n",
    "#排序并打乱存放车辆序号的集合\n",
    "random.shuffle(all_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d04842a-4009-410c-a385-6afd9632a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  load_data(pkl_list,label=True):\n",
    "    '''\n",
    "    输入pkl的列表，进行文件加载\n",
    "    label=True用来加载训练集\n",
    "    label=False用来加载真正的测试集，真正的测试集无标签\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for  each_pkl in pkl_list:\n",
    "        pic = open(each_pkl,'rb')\n",
    "        item= pickle.load(pic)#下载pkl文件\n",
    "        # 此处选取的是每个滑窗的最后一条数据，仅供参考，可以选择其他的方法，比如均值或者其他处理时序数据的网络\n",
    "        # 此处选取了前7个特征，可以需求选取特征数量\n",
    "        X.append(item[0][:,0:7][-1])\n",
    "        if label:\n",
    "            y.append(int(item[1]['label'][0]))\n",
    "    X = np.vstack(X)\n",
    "    if label:\n",
    "        y = np.vstack(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3d0dc3b-5cae-49b9-b649-46eeab85d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_files=[]\n",
    "\n",
    "for i in range(int(len(all_pkl_files)*0.9)):\n",
    "    train_pkl_files.append(all_pkl_files[i])\n",
    "test_pkl_files=[]\n",
    "for j in range(int(len(all_pkl_files)*0.9),len(all_pkl_files)):\n",
    "    test_pkl_files.append(all_pkl_files[j])\n",
    "\n",
    "X_train,y_train=load_data(train_pkl_files)\n",
    "X_test,y_test=load_data(test_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "473b1362-0e69-4a17-a334-fb4f1ab4dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "_mean = np.mean(X_train, axis=0)\n",
    "_std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - _mean) / (_std + 1e-4)\n",
    "X_test = (X_test - _mean) / (_std + 1e-4)\n",
    "y_train=y_train.ravel()\n",
    "y_test=y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51752da4-734b-4448-aa9b-54a414d4d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label,score):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, score, pos_label=1)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f021baa2-b321-4fa3-8d48-0f2dc63fdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.model_selection import cross_validate,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f9601fe-e946-434a-92aa-70c32d73cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin,tpe,hp,Trials\n",
    "from hyperopt.early_stop import no_progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c10001b5-5c83-499e-acc9-94e81114eb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8962035225048923"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#benchmark \n",
    "clf=GBC(random_state=4869)\n",
    "clf.fit(X,y)\n",
    "y=y.ravel()\n",
    "cv=KFold(n_splits=5,shuffle=True,random_state=4869)\n",
    "cross_validate(clf,X_train,y_train,cv=cv)['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d9e0c3c-f2d5-44d6-876e-b4b171b4b732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313168173974065"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=clf.predict_proba(X_test)[:,1]\n",
    "evaluate(y_test,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "322f4ff1-0bbe-45a0-9c1e-32c74015738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_objective(params):\n",
    "    clf=GBC(n_estimators=int(params['n_estimators'])\n",
    "            ,learning_rate=params['learning_rate']\n",
    "            ,loss = params['loss']\n",
    "            ,max_depth=int( params['max_depth'])\n",
    "            ,subsample=params['subsample']\n",
    "            ,max_features=params['max_features']\n",
    "            ,min_impurity_decrease=params['min_impurity_decrease']\n",
    "            ,random_state=4869,\n",
    "            verbose=False\n",
    "            )\n",
    "    cv=KFold(n_splits=5,shuffle=True,random_state=4869)\n",
    "    err=cross_validate(clf,X_train,y_train,cv=cv)['test_score'].mean()\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b531320b-9034-43ec-bba3-b999cc4fc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_hyperopt(max_eval=100):\n",
    "    trials=Trials()\n",
    "    early = no_progress_loss(100)\n",
    "    params_best = fmin(hyperopt_objective,\n",
    "                  space=para_grids,\n",
    "                  algo = tpe.suggest,\n",
    "                  verbose=True,\n",
    "                  max_evals=max_eval,\n",
    "                  trials=trials,\n",
    "                  early_stop_fn = early\n",
    "                  )\n",
    "    print(\"-------\"+'\\n'+\"best parameters:\",params_best)\n",
    "    return params_best,trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f267e183-f83a-411b-8145-7daa174c61af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n({'learning_rate': 0.65,\\n  'max_depth': 8.0,\\n  'max_features': 4,\\n  'n_estimators': 150.0,\\n  'subsample': 0.9},\\n <hyperopt.base.Trials at 0x7fe6b966c190>)\\n\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_grids = {\n",
    "    'n_estimators':hp.quniform('n_estimators',25,200,25)\n",
    "            ,'learning_rate':hp.quniform('learning_rate',0.05,2.05,0.05)\n",
    "            ,'loss': hp.choice('loss',[\"deviance\",\"exponential\"])\n",
    "            ,'max_depth' : hp.quniform('max_depth',2,10,2)\n",
    "            ,'subsample':hp.quniform('subsample',0.1,0.8,0.1)\n",
    "            ,'max_features':hp.choice('max_features',[3,4,5,6,7])\n",
    "            ,'min_impurity_decrease':hp.quniform('min_impurity_decrease',0,5,1)\n",
    "    \n",
    "    }\n",
    "\"\"\"\n",
    "{'learning_rate': 1.35,\n",
    "  'max_depth': 8.0,\n",
    "  'max_features': 0,\n",
    "  'n_estimators': 200.0,\n",
    "  'subsample': 0.8},\n",
    "\"\"\"\n",
    "# round 2  96\n",
    "\n",
    "para_grids = {\n",
    "    'n_estimators':hp.quniform('n_estimators',25,200,25)\n",
    "            ,'learning_rate':hp.quniform('learning_rate',0.5,0.8,0.05)\n",
    "            ,'loss': \"deviance\"\n",
    "            ,'max_depth' : 6\n",
    "            ,'subsample':hp.quniform('subsample',0.6,1.0,0.05)\n",
    "            ,'max_features':hp.choice('max_features',[3,4,5])\n",
    "            ,'min_impurity_decrease':0\n",
    "    }\n",
    "\"\"\"\n",
    "({'learning_rate': 0.6000000000000001,\n",
    "  'loss': 1,\n",
    "  'max_depth': 6.0,\n",
    "  'max_features': 1,\n",
    "  'n_estimators': 75.0,\n",
    "  'subsample': 0.6000000000000001},\n",
    " <hyperopt.base.Trials at 0x7fe6b983d100>)\n",
    " \"\"\"\n",
    "#round 3\n",
    "\"\"\"\n",
    "({'learning_rate': 0.65,\n",
    "  'max_depth': 8.0,\n",
    "  'max_features': 4,\n",
    "  'n_estimators': 150.0,\n",
    "  'subsample': 0.9},\n",
    " <hyperopt.base.Trials at 0x7fe6b966c190>)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8db2f5c4-4b9d-44c8-9948-af46237e2f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [09:15<00:00, 18.50s/trial, best loss: 0.9027788649706459]\n",
      "-------\n",
      "best parameters: {'learning_rate': 0.75, 'max_features': 1, 'n_estimators': 200.0, 'subsample': 0.6000000000000001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.75,\n",
       "  'max_features': 1,\n",
       "  'n_estimators': 200.0,\n",
       "  'subsample': 0.6000000000000001},\n",
       " <hyperopt.base.Trials at 0x7fe6ab86b790>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_hyperopt(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "761922be-2be4-4067-817b-8aa8a3e3d2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.75, max_depth=6, max_features=4,\n",
       "                           min_impurity_decrease=0, n_estimators=150,\n",
       "                           random_state=4869, subsample=0.6, verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GBC(n_estimators=150\n",
    "            ,learning_rate=0.75\n",
    "            ,max_depth=6\n",
    "            ,subsample=0.6\n",
    "            ,max_features=4\n",
    "            ,min_impurity_decrease=0\n",
    "            ,random_state=4869,\n",
    "            verbose=False\n",
    "            )\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90bb79a8-b0e1-4d53-8713-5fa2786e7f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93649975295912"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=clf.predict_proba(X_test)[:,1]\n",
    "evaluate(y_test,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1d5aa99d-70da-4694-b9da-a3a70825b460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6234/6234 [00:00<00:00, 746361.75it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path3='./data/Test_A'\n",
    "test1_files = glob(data_path3+'/*.pkl')\n",
    "X_val,_=load_data(test1_files,label=False)\n",
    "_mean = np.mean(X_val, axis=0)\n",
    "_std = np.std(X_val, axis=0)\n",
    "X_val = (X_val - _mean) / (_std + 1e-4)\n",
    "y_val_pred = clf.predict(X_val) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_val_scores = clf.predict_proba(X_val)[:,1]\n",
    "\n",
    "predict_result={}\n",
    "for i in tqdm(range(len(test1_files))):\n",
    "    file=test1_files[i]\n",
    "    name=file.split('/')[-1]\n",
    "    predict_result[name]=y_val_scores[i]\n",
    "predict_score=pd.DataFrame(list(predict_result.items()),columns=['file_name','score'])#列名必须为这俩个\n",
    "predict_score.to_csv('submision.csv',index = False) #保存为比赛要求的csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0a001-e4ce-4826-a2eb-01272f16240e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
