{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cf795f-632d-426e-b9b7-e7e6f09319be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "import torch\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder, check_array, inner_autoencoder, check_is_fitted, \\\n",
    "    pairwise_distances_no_broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ca8940-533d-4a11-97e5-3f71b23e67d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235da2cc-5d72-41fa-8ab1-4504fec1a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28389/28389 [00:01<00:00, 15584.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path='./data/Train'#存放数据的路径\n",
    "pkl_files = glob(data_path+'/*.pkl')\n",
    "ind_pkl_files = []#存放标签为0的文件\n",
    "ood_pkl_files = []#存放标签为1的文件\n",
    "for each_path in tqdm(pkl_files):\n",
    "    pic = open(each_path,'rb')\n",
    "    this_pkl_file= pickle.load(pic)#下载pkl文件\n",
    "    if this_pkl_file[1]['label'] == '00':\n",
    "        ind_pkl_files.append(each_path)\n",
    "    else:\n",
    "        ood_pkl_files.append(each_path)\n",
    "\n",
    "random.seed(0)\n",
    "#排序并打乱存放车辆序号的集合\n",
    "random.shuffle(ind_pkl_files)\n",
    "random.shuffle(ood_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816ab92e-a5a0-4379-8ac0-583ee06b6168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16393673605974146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_=len(ood_pkl_files)/(len(ind_pkl_files)+len(ood_pkl_files))\n",
    "percentage_\n",
    "#0.163 并没那么悬殊的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544fef08-9e39-47e2-bdd4-6d6e2253c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_files=[]\n",
    "for i in range(len(ind_pkl_files)//4):\n",
    "    train_pkl_files.append(ind_pkl_files[i])\n",
    "# 选取训练集中正常片段的1/4作为训练集，正常片段的剩余3/4和异常片段作为测试集\n",
    "test_pkl_files=[]\n",
    "for j in range(len(ind_pkl_files)//4,len(ind_pkl_files)):\n",
    "    test_pkl_files.append(ind_pkl_files[j])\n",
    "for item in ood_pkl_files:\n",
    "    test_pkl_files.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e416ad8-e82c-4789-8225-d4a69a731c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  load_data(pkl_list,label=True):\n",
    "    '''\n",
    "    输入pkl的列表，进行文件加载\n",
    "    label=True用来加载训练集\n",
    "    label=False用来加载真正的测试集，真正的测试集无标签\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for  each_pkl in pkl_list:\n",
    "        pic = open(each_pkl,'rb')\n",
    "        item= pickle.load(pic)#下载pkl文件\n",
    "        # 此处选取的是每个滑窗的最后一条数据，仅供参考，可以选择其他的方法，比如均值或者其他处理时序数据的网络\n",
    "        # 此处选取了前7个特征，可以需求选取特征数量\n",
    "        X.append(item[0][:,0:7][-1])\n",
    "        if label:\n",
    "            y.append(int(item[1]['label'][0]))\n",
    "    X = np.vstack(X)\n",
    "    if label:\n",
    "        y = np.vstack(y)\n",
    "    return X, y\n",
    "\n",
    "X_train,y_train=load_data(train_pkl_files)\n",
    "X_test,y_test=load_data(test_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b256d9c-32b9-486f-b410-888025b57692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5933, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c7afa5f-9fe2-45e6-b672-46bf9e51e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "_mean = np.mean(X_train, axis=0)\n",
    "_std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - _mean) / (_std + 1e-4)\n",
    "X_test = (X_test - _mean) / (_std + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d74eea-5f54-4fbc-ac1b-31a84686b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyODDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyOD Dataset class for PyTorch Dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y=None, mean=None, std=None):\n",
    "        super(PyODDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()#将tensor类型转换列表格式\n",
    "        sample = self.X[idx, :]\n",
    "\n",
    "        # if self.mean.any():\n",
    "        #     sample = (sample - self.mean) / (self.std + 1e-5)\n",
    "        #torch.from_numpy()将numpy类型转换为tensor类型\n",
    "        return torch.from_numpy(sample), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ecc027-6c35-4e98-b6ab-19fb0f505bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car_AutoEncoder(AutoEncoder):\n",
    "    \n",
    "    '''\n",
    "    使用autoencoder 来进行模型的训练，默认采用无监督的训练方式\n",
    "    '''\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # validate inputs X and y (optional)\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "\n",
    "        n_samples, n_features = X.shape[0], X.shape[1] #获取样本个数和特征个数\n",
    "\n",
    "        # 是否进行预处理操作\n",
    "        if self.preprocessing:\n",
    "            self.mean, self.std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "            train_set = PyODDataset(X=X, mean=self.mean, std=self.std)\n",
    "\n",
    "        else:\n",
    "            train_set = PyODDataset(X=X)\n",
    "        #构建数据生成器\n",
    "        train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=self.batch_size,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "        \n",
    "        self.model = inner_autoencoder(\n",
    "            n_features=n_features,\n",
    "            hidden_neurons=self.hidden_neurons,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            batch_norm=self.batch_norm,\n",
    "            hidden_activation=self.hidden_activation)\n",
    "\n",
    "        #将model放入device中\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # 训练自动编码器以找到最佳编码器\n",
    "        self._train_autoencoder(train_loader)\n",
    "\n",
    "        self.model.load_state_dict(self.best_model_dict)\n",
    "        self.decision_scores_ = self.decision_function(X)#获得输入样本的异常得分\n",
    "        \n",
    "        self._process_decision_scores()  \n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X): \n",
    "        \"\"\"使用拟合的检测器预测X的原始异常分数。\n",
    "\n",
    "            输入样本的异常分数是基于不同的检测器算法。为保持一致性，离群值分配为异常分数越大的。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            形状的numpy数组（n_samples，n_features）训练输入样本。仅接受稀疏矩阵，如果它们由基础估计器支持。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        anomaly_scores : numpy array of shape (n_samples,)\n",
    "            形状的numpy数组（n_samples，）输入样本的异常得分。\n",
    "        \"\"\"\n",
    "        #对估算器执行is_fitted验证。通过验证是否存在拟合属性（以下划线结尾）来检查估计量是否拟合，否则通过给定消息引发NotFittedError。此实用程序旨在由估计器本身在内部使用，通常在其自己的预测/变换方法中使用。\n",
    "        check_is_fitted(self, ['model', 'best_model_dict'])\n",
    "        # X = check_array(X)\n",
    "\n",
    "        # note the shuffle may be true but should be False\n",
    "        if self.preprocessing:\n",
    "            dataset = PyODDataset(X=X, mean=self.mean, std=self.std)\n",
    "        else:\n",
    "            dataset = PyODDataset(X=X)\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                                 batch_size=self.batch_size,\n",
    "                                                 shuffle=False) #要设置为False\n",
    "        # enable the evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # construct the vector for holding the reconstruction error\n",
    "        outlier_scores = np.zeros([X.shape[0], ])#形状为（X.shape[0],)\n",
    "        with torch.no_grad():\n",
    "            for data, data_idx in dataloader:\n",
    "                data_cuda = data.to(self.device).float()\n",
    "                # this is the outlier score\n",
    "                outlier_scores[data_idx] = pairwise_distances_no_broadcast(\n",
    "                    data, self.model(data_cuda).cpu().numpy())\n",
    "\n",
    "        return outlier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05e1c8bb-b2ea-4123-b3d8-3f4de5557ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.568735975644229"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "clf=IForest()\n",
    "clf.fit(X_train)\n",
    "y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "AUC1=evaluate(y_test,y_test_scores)\n",
    "AUC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d29abe6d-9f93-477d-bfae-5b7a1ed50489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48156872496183123"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "clf1=HBOS()\n",
    "clf1.fit(X_train)\n",
    "y_test_pred = clf1.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_test_scores = clf1.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "AUC1=evaluate(y_test,y_test_scores)\n",
    "AUC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2562c2c1-b048-4124-8715-fcc2b53a4da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyod/models/lscp.py:383: UserWarning: The number of histogram bins is greater than the number of classifiers, reducing n_bins to n_clf.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/usr/local/lib/python3.8/dist-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4643175995975788"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyod.models.lscp import LSCP\n",
    "clf2=LSCP([clf,clf1])\n",
    "clf2.fit(X_train)\n",
    "y_test_pred = clf2.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_test_scores = clf2.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "AUC1=evaluate(y_test,y_test_scores)\n",
    "AUC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6273e6e7-8dc4-4cd1-b6d8-23715e20e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了便于复现这里固定了随机种子\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def train(X_train,X_test,hidden_neurons,learning_rate,epochs,batch_size,contamination,drop_out,hidden_activation):\n",
    "    same_seeds(42)\n",
    "    clf_name = 'auto_encoder'\n",
    "    clf = Car_AutoEncoder(hidden_neurons=hidden_neurons,  batch_size=batch_size, epochs=epochs,learning_rate=learning_rate,\n",
    "                                    dropout_rate=drop_out,contamination=contamination,hidden_activation=hidden_activation)\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    y_train_pred = clf.labels_ # 返回训练数据上的分类标签 (0: 正常值, 1: 异常值) # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # 返回训练数据上的异常值 (分值越大越异常)# raw outlier scores\n",
    "    y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "    return clf, y_test_scores\n",
    "\n",
    "def evaluate(label,score):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, score, pos_label=1)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1ae0d0-ffc9-4770-8002-1f35faba649b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'same_seeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m drop_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      7\u001b[0m hidden_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43msame_seeds\u001b[49m(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     10\u001b[0m clf \u001b[38;5;241m=\u001b[39m Car_AutoEncoder(hidden_neurons\u001b[38;5;241m=\u001b[39mhidden_neurons,  batch_size\u001b[38;5;241m=\u001b[39mbatch_size, epochs\u001b[38;5;241m=\u001b[39mepochs,learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m     11\u001b[0m                                      dropout_rate\u001b[38;5;241m=\u001b[39mdrop_out,contamination\u001b[38;5;241m=\u001b[39mcontamination,hidden_activation\u001b[38;5;241m=\u001b[39mhidden_activation)\n\u001b[1;32m     12\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'same_seeds' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_neurons=[32,64,64,32]\n",
    "learning_rate=0.03\n",
    "epochs=15\n",
    "batch_size=640\n",
    "contamination=0.005\n",
    "drop_out=0.2\n",
    "hidden_activation='sigmoid'\n",
    "\n",
    "same_seeds(42)\n",
    "clf = Car_AutoEncoder(hidden_neurons=hidden_neurons,  batch_size=batch_size, epochs=epochs,learning_rate=learning_rate,\n",
    "                                     dropout_rate=drop_out,contamination=contamination,hidden_activation=hidden_activation)\n",
    "clf.fit(X_train)\n",
    "y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e69a10e-e3c5-4bf7-8042-9d5819b911a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6452516501166173"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC1=evaluate(y_test,y_test_scores)\n",
    "AUC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e85dd9-bb8a-4fc0-9699-f0dcdf3e722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path3='./data/Test_A'\n",
    "test1_files = glob(data_path3+'/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9b3a8c-546c-4997-b973-e205b879c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6234/6234 [00:00<00:00, 57974.07it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val,_=load_data(test1_files,label=False)\n",
    "_mean = np.mean(X_val, axis=0)\n",
    "_std = np.std(X_val, axis=0)\n",
    "X_val = (X_val - _mean) / (_std + 1e-4)\n",
    "y_val_pred = clf.predict(X_val) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_val_scores = clf.decision_function(X_val)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "predict_result={}\n",
    "for i in tqdm(range(len(test1_files))):\n",
    "    file=test1_files[i]\n",
    "    name=file.split('/')[-1]\n",
    "    predict_result[name]=y_val_scores[i]\n",
    "predict_score=pd.DataFrame(list(predict_result.items()),columns=['file_name','score'])#列名必须为这俩个\n",
    "predict_score.to_csv('submision.csv',index = False) #保存为比赛要求的csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778844a-00b1-46b0-bd3f-d76f8e2c08af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
